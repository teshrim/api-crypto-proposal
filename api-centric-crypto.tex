\section{API-centric Cryptography}
The security community has published extensively on the \emph{usability} of
APIs; recent publications include \cite{ABF+,HHL+17,IKND16}.  Intuitively, if an
API is easy to use correctly (and hard to use \emph{incorrectly}),
developers are more likely to build secure applications on top of it.
%
Our approach is complementary, focusing on the relationships between
functionalities that APIs present and the primitives
that crypto theory provides. We take the position that, in practice, API design
is primarily driven by non-security requirements (e.g. functionality, adoption,
deployment).
%
As such, it is incumbent upon us to take an \emph{API-centric} view of the
primitives and protocols that we formalize.  In the remainder of this section,
we discuss specific areas to which we will apply this API-centric perspective.
%
%\cpnote{I think we need to define \emph{API-centric} in the intro.}

%Note that this is a preliminary list of areas, based on prior results and current considerations.

\paragraph{Understanding an API's customers. }
It is important to recognize that there are at least two types of ``customers''
to consider when taking an API-centric viewpoint on cryptography. The first we
have already mentioned, namely \emph{application developers}. Application developers
are largely concerned about functionality, and have relatively little expertise
in cryptography. They are likely to want a simple, semantically-intuitive,
high-level interface, e.g.
\begin{align*}
\varfont{SecureSocketHandle}&\gets\algfont{SecureOpen}(\varfont{ReceiverID}), \\
\varfont{Status}&\gets\algfont{SecureSend}(\varfont{SecureSocketHandle, Msg}),\\
  (\varfont{Msg}, \varfont{Status}) &\gets\algfont{SecureReceive}(\varfont{SecureSocketHandle}), \\
\varfont{Status}&\gets\algfont{SecureClose}(\varfont{SecureSocketHandle}).
\end{align*}
%
where the type and structure of the data object \varfont{Msg} would be
separately specified, e.g. it may include associated data or attributes, in
addition to the actual plaintext.
%
The object \varfont{Status} indicates the channel's health e.g, it may have been
torn down by the peer, or the destination address may be unreachable.

The above API neatly hides an enormous amount of plumbing implemented by the
\emph{security engineer}. There are a number of components to put together. The
high-level tasks are to authenticate the peer, exchange a key, use the key to
transmit the message, and securely tear down the session. Designing and
implementing such a protocol gets into the weeds quite quickly. This is an area
where having good APIs for things like digital signatures, message
authentication codes, and encryption is extremely helpful; even so, it is rarely
apparent how these are to be securely composed. This difficulty is compounded by
the fact that the protocol needs to be as efficient as possible, as application
developers (and users of the applications in turn) are generally unwilling to
pay a heavy price for security.
%
To illustrate these issues, consider the following API for
unilaterally\footnote{By unilaterally, we mean that the party opening the
channel authenticates the peer, but not the other way around.}
authenticated key exchange:
\begin{align*}
  \varfont{SocketHandle} &\gets\algfont{Open}(\varfont{ReceiverAddr}), \\
  (\varfont{Key}, \varfont{Status}) &\gets \algfont{NegotiateKey}(
    \varfont{SocketHandle}, \varfont{ReciverCert}, \varfont{CertAuth})
\end{align*}
where $(\varfont{ReceiverAddr}, \varfont{ReceiverCert})$ comprise
\varfont{ReceiverID} (above).  First, note that the root-of-trust,
\varfont{CertAuth}, is implicit in the first API. Unless we are to trust the
developer to manage certificates (as many existing APIs do~\cite{xxx}\cpnote{the
self-signed cert problem in Android dev}), then the security engineer needs to
make this transparent to upper levels. Second, there are numerous ways to
realize \algfont{NegotiateKey}, each with varying degrees of security and
efficiency. Third, modern protocols, such as TLS $1.3$, are designed so that
application data may be piggy-backed on the handshake. As such, providing an
opaque interface is likely not desirable. In general, the ``right'' level of
exposure to the application developer or security engineer is likely highly
task-dependent.
%
\if{0}
  (Consider for example, the well-known defficiency in TLS version $1.2$ (and
  older); The final \textsc{Finish} message being MACed renders it impossible to
  prove security in the key-indistiguishiblity sense, which means the handshake
  is not directly composable with the record protocol.)
\fi
%
\if{0}
\cpnote{It might be helpful to give an example of something exposed to the
``security engineer.''}\tsnote{Agreed.  So what would be the
corresponding API for security engineers?  I'm not sure, myself.  I
would think that the SE actually has an API for the components that
are needed to build up things like $\algfont{SecureSend}$, not a
version of $\algfont{SecureSend}$ that surfaces more inputs/outputs.
But if you look at that ``semantic API'' paper, the API they give to
the security engineer is very spartan, with all of the crypto actually
assumed in a Java library.  So I'm not sure what the right thing to do
is, here.  Thoughts?}
\todo{Need to finish out this text before leading into the task...}
\fi

\begin{task}
  We will carry out a detailed survey of existing APIs exposed by
  cryptographic libraries.  The goals will be to understand exactly
  what are the effective primitves being exported, to build a
  framework within with patterns across libraries can be established,
  to set metrics for comparing the complexity of the primitives
  exposed, and so on.  This will support multiple subsequent
  tasks.
\end{task}

Two of the most important secure functionalities needed by application
developers are to send and receive messages (data-in-flight), and to
read and write from storage (data-at-rest).  We will explore [[insert
places where we expect to find APIs for these]] ...

\begin{task}
Application developer APIs for secure send/receive of messges
(data-in-flight) and secure read/write from storage (data-at-rest).  What are
the implied primitives, and what are the security properties that developers
assume are provided.
\end{task}

\paragraph{Standardized APIs. }
%\cpnote{Do you think there's too much detail here? The hedged PKE stuff has a
%lot less...}
%\tsnote{There may ultimately be too much here, but I don't
%know yet.  Anyway, it's fine to have some sections more detailed than
%others, especially if some allow you to really trumpet the PI's chops.}
%
In~\cite{SSW}, PI Shrimpton and coauthors gave a provable-security treatment to
the design and analysis of so-called ``cryptographic APIs'', standardized in the
PKCS\#11 document.\footnote{See
\url{https://www.oasis-open.org/committees/tc_home.php?wg_abbrev=pkcs11} for the
latest spec.} That standard details an interface by which one may interact with
cryptographic tokens (e.g. smart cards, USB devices, enterprise-grade HSMs) that
are trusted to perform key-manangement duties, enforcement of policies for the
use of stored keys, and a limited number of asymmetric- and symmetric-key crypto
operations.  These tokens support a variety of applications, including entity
authentication, certification authorization, SSL/TLS acceleration, and interbank
communication.
%

Our approach in this paper was API-centric, in that we took the PKCS\#11
standard as the reference point, and defined from it a new cryptographic-API
primitive.
%
%\cpnote{Why ``cryptographic API primitive'' instead of ``cryptographic
%  API''?}\tsnote{Because I have never liked calling the object whose
%  syntax we established, and whose security notions we developed, a
%  cryptographic API.  A cryptographic API exposes some effective primitive.}
%
We then formalized some of the intuitive notions of security for a
cryptographic API.  This was a complex undertaking, as one of the core
key-management functionalities is to allow the exporting and importing of keys
via ``key (un)wrapping'' operations.  (This supports, among other things, the
transportation of cryptographically protected keys between tokens.)  These keys
may have a variety of attributes associated to them that proscribe their usage,
e.g.\ this key may/may not be used to encrypt data (via a given API call), that
key may or may not be wrapped for future export, etc.  Thus, the internal state of
the key-management functionality changes as an attacker carries out permitted
API calls. (We note that works by Steele and
coauthors~\cite{KS13}\cpnote{Others?}
exploit this changing of internal state, sometimes in concert with
underspecification in standards and device documentation, to cause catastrophic
security breaks in HSMs.) Moreover, a real adversary may be in possession of one
or more tokens ---~keep in mind that these may be physically vulnerable devices,
such as USB sticks or smart cards~--- and these are subject to corruption.  As a
result, a victim token is asked to import adverasarially-known keys.  This can
cause many other keys under management by the victim to become (effectively)
corrupted, e.g. if the attributes of the imported key allow it to be used for
wrapping.
%

While~\cite{SSW} makes important progress in the analysis of
cryptographic APIs (in particular PKCS\#11), they do leave open some
interesting avenues.  For exmaple, their handling of attributes is
quite abstract, only indicating their influence on tokens as part of
the execution model.  But what one really wants are formal mechanisms and
security notions for reasoning about the enforcement of specific
policies, e.g. that certain keys may be used only by certain entities
and only for a given set of cryptographic operations.  Also,
\cite{SSW} does not consider the public-key primitives that are
typically exposed by tokens.  Finally, it would be useful to
understand the extent to which real tokens respect PKCS\#11 and, if we
find the model of~\cite{SSW} to be significantly disconnected from
these tokens (say, because tokens often take liberties with PKCS\#11,
or because other standards are gaining traction) then we should
revisit the models.

\begin{task}
  We will explore these interesting and important extensions
  to~\cite{SSW}: (1) formal mechanisms and
security notions for reasoning about the enforcement of specific
policies, (2) incorporating the public-key primitives that are
typically exposed by tokens, (3) establishing how closely tokens
adhear to PKCS\#11 and revisiting the formal models based on what we find.
\end{task}
%

\paragraph{Hedged Cryptography. }
Recent work by PI Shrimpton and coauthors~\cite{BPS} revisits the theory of
hedged public-key encryption (PKE)~\cite{BBN+} from an API-centric perspective.
%
The motivation for hedged PKE is quite practical. Traditional PKE schemes are
proved secure under the assumption that they have access to a source of uniform
random bits; but in practice, PKE schemes are implemented on systems that have
faulty RNGs, or where entropy is difficult to harvest.  In these cases, the
security guarantees proved in theory are, at best, voided; at worst, failure of
the RNG can lead to recovery of the plaintext.
%
Hedged PKE is designed to satisfy traditional notions of security when provided
uniform randomness, and still deliver useful security properties as the quality
of randomness degrades.  The most elegant construction of hedged PKE works like
this~\cite{BBN+,BH15}: synthesize fresh random bits by hashing all of the
encryption inputs (the public key, the message, the provided randomness), and
then use these bits as the randomness for an underlying PKE scheme.  In
practice, implementing this simple construction is surprisingly difficult, as
the high- and mid-level APIs presented by the most commonly used crypto
libraries (e.g. OpenSSL and significant forks thereof) \emph{do not} permit one
to specify the per-encryption randomness.\footnote{Other constructions of hedged
PKE that do not explicit require the ability to manipulate the encryption coins
are, likewise, difficult or impossible to implement via existing high- and
mid-level APIs.  In their cases, it is because the primitives that are needed do
not exist in common llibraries.}
In~\cite{BPS}, the theory of hedged
PKE is reconsidered from the perspective of what can be easily constructed given
what real APIs expose, and what provable security guarantees these can achieve.

Still, \cite{BPS} leaves open some important matters.  First of all, the
randomness sources in their models are stateless.  Most crypto libraries export
\emph{pseudorandom number generators with inputs}~\cite{BH05,DPR+13,ST15} for
providing random bits to library code and applications. These allow the
programmer to add entropy into the PRNG's internal state.  Additionally,
\cite{BPS} only considers PKE.


\begin{task}
We will push hedged PKE closer to practice by exploring the
consequences of sources that are PRNGs with input.  Minimally, this will require
a reconsideration of security notions and new constructions.  We will
implement the best schemes to evaluate performance (e.g. overhead
relative to plain PKE and the schemes from~\cite{BPS}) and interact
with library maintainers to facilitate deployment of our constructions.
\end{task}

\begin{task}
We will work to hedge other primitives against faulty randomness,
using appropriate models of the randomness sources, all from the
viewpoint of what real-world APIs expose.
\end{task}


\paragraph{Secure Channels. }
\if{0}
\tsnote{I like that you are making this point.  But I think
  the writing that follows is missing the mark.  Why?  Because you
  talk about protocols and implementations, but there's no clear
  reason that any of \emph{that} provides a secure channel either!
  The point I think you are trying to make is that a secure channel
  should provide a lot more than what an AEAD scheme does, and I
  agree: so explicitly say what a secure channel is supposed to provide!
  What do applications expect from them?  Give it another try :-) And
  tighten it up, too, please.  Set up the problem, pull out the
  surprising/important nuggets, make it clear what are the directions
  they suggest, and then write a couple of clear tasks.}
\fi
Perhaps the most practically important cryptographic functionality is the
secure channel, the task of which is to provide privacy and authenticity for
message flows between peers.
%
Over the last decade or so, \emph{authenticated encryption with associated data}
(AEAD) has emerged as an important ingredient for constructing secure channels.
%
Its syntax is easy to reason about from a theoretical point of view, and yet is
robust enough to encompass most tasks that practitioners encounter. Moreover,
notions like \emph{nonce-misuse resistant}~\cite{RS06} and
\emph{robust}~\cite{HKR15} authenticated encryption make AEAD schemes difficult
to (inadvertently) use incorrectly. These properties make AEAD an attractive
tool for designing protocols.
\if{0}{
  Indeed, schemes like AES-GCM and
  ChaCha20\mbox{-}Poly1305 are baked into the upcoming TLS $1.3$
  specification.\footnote{ See \url{https://tlswg.github.io/tls13-spec}.
}\fi

It is tempting to think that AEAD, on its own, provides a secure channel.  But
as recently pointed out by Badertscher \etal~\cite{BMM+15}, classical security
notions, such as those for AEAD ``do not capture in which contexts a scheme
satisyfying them can securely be used.'' Time and time again, bugs  in the
\emph{protocol logic} have been exploited to \emph{completely circumvent} the
security provided by the underlying crypto. This gap has spurred the study of
\emph{stateful} authenticate encryption schemes that model secure channels more
closely, such as the highly influential SSH paper~\cite{BKN02} and the analysis
of the TLS $1.2$ record layer by PI Shrimtpon~\cite{PRS11}. Boldyreva
\etal~\cite{DBPS12} later extended \cite{BKN02} to encompass the protocol-level
attack of \cite{APW09} that exploits fragmented delivery of the ciphertext stream. This
line of work has deepened our standing of how to build secure channels, but from
an API-centric perspective, these works omit a crucial detail.

Providing a reliable (but not secure) channel between any two hosts on the
Internet is the job of the TCP/IP protocol stack. TCP in particular is designed
so that application developers need not worry about the details at all.
Virtually all programming languages export an API for \emph{streaming data} over
TCP, whereby the sender stuffs in any number of bytes and expects that its peer
receives them in the order transmitted.  The alternative view (and the
conventional wisdom of the cryptographic community) is that channels provide
transport of a sequence of atomic messages between two parties.  TCP is
ubiquitous for the delivery of web content, and consequently, implementations of
the TLS record layer also export a streaming API. In OpenSSL (the most
widely-deployed implementation of TLS), \codefont{SSL\_write()} is used to write
bytes to the stream and \codefont{SSL\_read()} is used to read bytes from the
stream. An application developer can use this API just as she would use the
lower-level functionality for reliable transport, but with the added assurance
that the channel is secure.

Fischlin \etal~\cite{FPMG15} were the first (atleast in the cryptographic
community) to elucidate secure channels as data streams. (In \cite{BDSP12}, the
input messages are atomic; in works such as \cite{BFK+13,DLFK+17}, the
ciphertexts are atomic.)
%
Their syntax directly captures a streaming API, and their security notions
(privacy and authenticity) model an adversary who transmits ciphertext
``fragments'' over the channel, and may drop, inject, and reorder fragments at will.
This allows them to model streaming protocols (such as TLS) that divide the
message stream into discrete ``records'' and encrypt each individually before
transmitting. The peer may receive only a piece of a record, or
multiple records simultaneously.

We regard the work of Fischlin \etal as an
important step in an API-centric treatment of secure channels.
%
However, there remains a wide gap between their work and cryptographic practice.
In order to apply their methodology to a real protocol, one would need to
precisely specify it as a streaming secure channel (according to their
formalism) and provide a proof of security. This on its own is a complex
undertaking (cf. \cite{DLFK+17}), but it also places a heavy burden on the
security engineers. It is incumbent on them to implement this protocol
\emph{precisely}, and if the protocol needs to be changed (say, to address some
engineering constraint), then the cryptographer needs to provide a fresh proof.

A beautiful, yet largely-overlooked work by Rogaway and Stegers~\cite{RS09}
affords an opportunity to bridge this gap. Their observation is that when
cryptographers design protocols, they provide an abstraction that omits many
details relevant to implementing them on real systems. (They necessarily do
so for the reasons given above.)
%
They provide a framework for analyzing \emph{partially-specified protocols},
where the ``cryptographic core'' of the protocol is separated from the
``protocol details'' relevant to engineers. In the analysis, one assumes the
latter is utterly controlled by the adversary. This  allows the security
engineer a large degree of flexibility in designing the protocol without
compromising security.

\begin{task}\label{task:sc}
  \cpnote{This task supports the gaol of making \emph{crypto APIs easier to use
  securely}.}
  %
  We propose to apply Rogaway-Stegers methodology to streaming secure channels
  towards providing guidance in the design of the TLS 1.3 record layer.
\end{task}


\todo{Have another look at the online-AE paper. What do Fischlin \etal say
about it?}
\cpnote{Flischlin \etal say that OAE is unrelated to their work, although they
didn't read~\cite{HRRV15}. (Their OAE citations are prior work.) Nonetheless, I
tend to agree with them. First, the syntax is sufficiently different. Second,
the goals are different; \cite{HRRV15} want to model \emph{online} and
\emph{constant-space} encryption/decryption; in~\cite{FPMG15} neither of these
are mandated.}

\todo{I feel like we are missing an important task here, having to do
with understanding what are the current APIs for secure channels,
how those align with theoreticians' viewpoint(s) on secure channels,
looking for the ``right'' API/syntax for secure channels, i.e. one
that supports what applications expect, etc.}
%
\cpnote{To me this is already done. \cite{FPMG15} syntax is quite close to real
APIs. The syntax I've worked out for this paper is \emph{even closer}, but I
don't think that's the main contribution of the paper. The main contribution is
the security model.}

\paragraph{Authenticated Key-Exchange. }
%
%Task~\ref{task:sc} deals with communication between parties who share
%a key.  
%In practice, a  component of a secure channel is the initial key exchange.
%
Since the seminal work of Bellare and Rogaway~\cite{BR93}, the setting in which
authenticated key exchange (AKE) is studied has not changed
much~\tsnote{what do you mean by ``the setting'' in which it is
  studied?  And can you justify your claim that it (whatever it is)
  has not changed much?}; meanwhile, the needs of
real-world protocols have evolved substantially over the years. Take the TLS
handshake  as an example.
%
First, the vast majority of the literature has focused on the case of
\emph{mutual} AKE (MAKE), where both client and server wish to authenticate
the other. In fact, virtually all TLS handshakes on the Internet are only
\emph{unilaterally} authenticated (UAKE)~\cite{xxx}. (The client wishes to
verify the server's identity.)
%
Second, TLS offers features that break with the Bellare-Rogaway model
altogether. For example, Bhargavan et al.~\cite{bhargavan2014proving} point
out (a) that handshakes share states \emph{across session} (in
Bellare-Rogaway each session has its own state), and that (b) the same
material may be used by the same entity in \emph{different protocols}
(requires the underlying algorithms be \emph{agile}, a
la~\cite{acar2010cryptographic}).
%
Third, an important consideration in the upcoming TLS 1.3
specification~\cite{tls13} is \emph{session resumption}, where the goal is
to piggy-back a fresh key exchange on the data channel between a client and
server who have already performed the full handshake. This feature is
crucial from an engineering perspective, but as is well-known~\cite{xxx}, we
cannot provide the same level of security for the message on which we are
piggy-backing the exchange as is possible for subsequent messages.

These issues are some of the many that point to a gap between how programmers
expect they should be able to use cryptography, and how cryptography is to
be used securely. This presents an opportunity to distill from design
patterns in existing KE protocols (TLS~\cite{xxx}, IPSec~\cite{xxx}, Signal~\cite{xxx}, Noise~\cite{xxx}, etc.) an
abstraction (and corresponding API) that cleanly captures the needs of
software engineers.
  %
  A promising direction is to begin with Dodis and
  Fiore~\cite{dodis2017unilateral}, who show that security in this setting is
  much easier to model than the more general MAKE setting of Bellare-Rogaway.
  An approach by Krawczyk~\cite{krawczyk2016unilateral-to-mutual} can be
  employed to transform a UAKE scheme to a MAKE scheme.
  %
  Dodis and Fiore define a natural primitive they call
  \emph{comfirmed encryption} for KEM-based UAKE, which has an API that, we
  feel, is intuitive for security engineers.
  %
  A limitation, however, is that comfirmed encryption cannot provide forward
  secrecy on its own. 

\begin{task}
%\cpnote{\emph{Propose an API} for a field that needs one.}
We will elucidate \tsnote{``Elucidate'', or establish?} the syntax and
security for DH-based UAKE whose API is similarly
intuitive. 
\end{task}

Going in a different direction, Rogaway and Stegers~\cite{RS09} 
  suggest their methodology could be extended from entity
  authentication to AKE. We find it somewhat remarkable that this task
  has not been undertaken, and we propose to do so. \todo{This needs a
    bit more lead-in.}
\begin{task}
%\cpnote{Make it easier to use APIs correctly.}
We will apply the partially-specified-protocol methodology of~\cite{RS09} to authenticated key-exchange.
  %
\end{task}

\todo{Is there more here?  What about the ideas that
  Trevor Perrin suggested, specifically for AKE?  I feel like we are
  missing a chance to build in more tasks and show more vision}

\paragraph{Ease of Correct Implemenation as Security Property. }

%\paragraph{Prior Work.}
\todo{Write.}\tsnote{Chris, at your suggestion, I've downgraded this
  former section to a paragraph-subsection within API-centric
  crpyto. Let's see how it works.}

\tsnote{May need to do some digging outside of crypto here!}

\todo{Rogaway's Authentication without Ellision paper}
\cpnote{This is what their framework buys us. The full protocol is divided into the
``protocol core'' (PC) and the ``protocol details'' (PD). The PC is specified
by the cryptographer and the PD is specified by the engineer. The PC ``calls''
the PD in the course of the protocols execution. In the security analysis, we
assume the PD is utterly controlled by the adversary. This allows cryptographers
to ``partially specify'' a protocol that remains secure even as engineer's
requirements change; the PC must be implemented precisely, but the PD may change
to suit the programmers' needs.
%
So in this framework we're not formalizing ``implementation risk'' directly;
instead, we're proving security of protocols that have flexibility in their
implementation. It says precisely what parts you \emph{must} get right in order
to have security, and what parts are not crucial.
}
